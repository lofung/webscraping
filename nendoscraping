#python3

import requests
from bs4 import BeautifulSoup
import re
from twitterscrap import tweetscrape

#ask for target
choice = input("input choice \n1: scrape mikatan blog \n2: input scrape target \nENTER: hit enter to scrape recent tweet from @figure_alt with keyword カホタン and ねんどろ")

if choice =="1":
    bloglink="https://ameblo.jp/gsc-mikatan/"
elif choice =="2":
    bloglink = input("input download target or hit enter for default")
    if bloglink == "":
        print('-------------')
        print("nothing input")
        quit()
else:
    bloglink = tweetscrape()

#status 200 = good
page = requests.get(bloglink)
print("Response of page status code " + str(page.status_code))
print("-------------------------------------")

soup = BeautifulSoup(page.content, "lxml")
imagelist = []
imagelistcorrected = []

for a in soup.find_all("a" , href=True):
    if re.findall(r".+(?=jpg|png|jpeg)",a['href']):
    # find out if the url contain jpg or png or jpeg , if not return a empty list. empty list is False
        #print(a['href'])
        imagelist.append(a['href'])

#print list to verify
imagelist.sort()
print(imagelist)


keyword = input('enter keyword shown in picture link to sort for download or hit ENTER for no sort \n')
#sort for keyword only, others not downloaded.
for s in imagelist:
    if str(keyword) in s:
        imagelistcorrected.append(s)

#download appendix for no reason
j = 0

#remember to change directory
for k in imagelistcorrected:
    picture_request = requests.get(k)
    #download
    with open("C:\\Users\\Belun\\Downloads\\temp\\" + str(j) + k[-13:], 'wb') as f:
         f.write(picture_request.content)
    j=j+1
    print(k + " downloaded")

print('--------------------------')
print('download done')



